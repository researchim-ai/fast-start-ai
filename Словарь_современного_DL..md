# Словарь современного Deep Learning

## Общий DL

**Deep Learning – Глубокое обучение**  
Область машинного обучения, использующая нейронные сети с множеством слоёв для решения сложных задач. Эта методика позволяет моделям автоматически извлекать высокоуровневые абстракции из данных, что делает её эффективной для распознавания образов, обработки естественного языка и других сложных задач.

**Neural Network – Нейронная сеть**  
Модель, состоящая из взаимосвязанных нейронов (узлов), имитирующих работу человеческого мозга для обработки информации. Нейронные сети способны моделировать сложные зависимости между входными и выходными данными, что делает их ключевым элементом в решении задач классификации, регрессии и генерации данных.

**Feedforward Neural Network – Прямой нейронная сеть**  
Базовый тип сети, в которой данные проходят от входного слоя к выходному без обратных связей. Эти сети используются для решения простых задач, где важна прямая связь между входом и выходом, без учета временных зависимостей.

**Perceptron – Перцептрон**  
Элементарная модель нейрона, принимающая входные данные, обрабатывающая их и выдающая результат. Перцептрон служит основой для более сложных архитектур и демонстрирует принцип линейной классификации, где результат определяется взвешенной суммой входов.

**Fully Connected Layer – Полносвязный слой**  
Слой, где каждый нейрон соединён с каждым нейроном предыдущего слоя. Такой слой позволяет моделям обучаться сложным нелинейным зависимостям, поскольку каждая связь имеет свой вес, который оптимизируется в процессе обучения.

**Activation Function – Функция активации**  
Функция, применяемая к сумме взвешенных входов нейрона для введения нелинейности (например, ReLU, sigmoid, tanh). Функции активации помогают моделям решать сложные задачи, преобразуя линейные комбинации входов в нелинейные выходы, что расширяет возможности сети.

**Softmax – Софтмакс**  
Функция, преобразующая вектор значений в вероятностное распределение, часто используемая для многоклассовой классификации. Она нормализует выходы сети так, чтобы сумма всех значений равнялась единице, что позволяет интерпретировать их как вероятности принадлежности к классам.

**Loss Function – Функция потерь**  
Мера ошибки, определяющая разницу между предсказанными и истинными значениями, которую модель стремится минимизировать. Функция потерь служит критерием качества работы модели и направляет процесс оптимизации, позволяя корректировать веса сети.

**Gradient Descent – Метод градиентного спуска**  
Алгоритм оптимизации для корректировки весов модели в направлении наискорейшего уменьшения функции потерь. Метод итеративно обновляет параметры модели, используя производные функции потерь, чтобы найти минимум в пространстве параметров.

**Momentum – Моментум**  
Метод ускорения сходимости оптимизации за счёт учёта предыдущих обновлений весов для сглаживания траектории. Этот подход помогает преодолеть локальные минимумы и ускоряет сходимость, особенно в глубоких моделях с большим количеством параметров.

**Adam – Адам**  
Популярный алгоритм оптимизации, объединяющий адаптивное вычисление моментов и моментум для ускорения сходимости. Adam автоматически настраивает скорость обучения для каждого параметра, что позволяет эффективно обучать модели с различной динамикой обновлений.

**Backpropagation – Обратное распространение ошибки**  
Метод расчёта градиентов, используемый для обновления весов нейронной сети после каждого прохода обучения. Он распространяет ошибку от выходного слоя к входному, позволяя корректировать веса на основе вклада каждого нейрона в итоговую ошибку.

**Optimizer – Оптимизатор**  
Алгоритм (например, SGD, Adam, RMSprop), используемый для обновления параметров модели в процессе обучения. Оптимизаторы выбираются в зависимости от задачи и структуры модели, помогая находить эффективное решение за счет корректировки весов.

**Regularization – Регуляризация**  
Набор техник для уменьшения переобучения модели, включая L1, L2, Dropout и Early Stopping. Регуляризация добавляет ограничения или штрафы к функции потерь, что помогает модели лучше обобщать информацию и избегать слишком сильной адаптации к тренировочным данным.

**Dropout – Отбрасывание**  
Метод регуляризации, при котором случайно исключаются некоторые нейроны во время обучения для уменьшения зависимости от конкретных путей. Эта техника предотвращает чрезмерное запоминание обучающих данных, улучшая обобщающие способности модели.

**Batch Normalization – Нормализация пакета**  
Техника, нормализующая входы каждого слоя по мини-пакетам данных для стабилизации и ускорения обучения. Нормализация помогает снизить влияние изменений распределения входных данных, что способствует более быстрой и стабильной сходимости.

**Learning Rate – Скорость обучения**  
Гиперпараметр, определяющий величину шага при обновлении весов модели. Правильный выбор скорости обучения критически важен: слишком высокий может привести к нестабильности, а слишком низкий — к медленной сходимости.

**Learning Rate Scheduler – Планировщик скорости обучения**  
Механизм динамического изменения скорости обучения в процессе тренировки для улучшения сходимости. Снижение скорости обучения на поздних этапах помогает модели тонко настраиваться, минимизируя риск перескока оптимального решения.

**Epoch – Эпоха**  
Один полный проход по всему набору тренировочных данных. Каждая эпоха позволяет модели обновить свои параметры, проходя через все примеры обучающего набора, что способствует постепенному снижению ошибки.

**Mini-Batch – Мини-пакет**  
Небольшая часть обучающих данных, используемая для одного шага обновления весов, что делает обучение более стабильным. Разбиение данных на мини-пакеты позволяет снизить вычислительную нагрузку и ускорить процесс оптимизации.

**Weight Initialization – Инициализация весов**  
Процесс задания начальных значений параметров нейронной сети, влияющий на скорость и качество обучения. Хорошая инициализация помогает избежать проблем, связанных с затухающими или взрывающимися градиентами, и способствует более быстрому обучению.

**Transfer Learning – Трансферное обучение**  
Метод адаптации модели, предварительно обученной на одном наборе данных, для решения смежной задачи. Этот подход позволяет использовать уже извлеченные признаки, что значительно сокращает время обучения и повышает точность в новых задачах.

**Model Pruning – Обрезка модели**  
Процесс удаления избыточных параметров для уменьшения размера модели и повышения её эффективности. Обрезка помогает снизить вычислительную сложность без значительной потери точности, что особенно полезно для развертывания моделей на устройствах с ограниченными ресурсами.

**Quantization – Квантование**  
Снижение точности представления параметров модели для ускорения вычислений и экономии памяти. Этот метод позволяет уменьшить размер модели и повысить скорость вывода, особенно на аппаратуре с низкой производительностью.

**Ensemble Methods – Ансамблевые методы**  
Подход, при котором несколько моделей объединяются для получения более точных и устойчивых предсказаний. Ансамблирование помогает компенсировать ошибки отдельных моделей, улучшая обобщающую способность системы.

**Cross-Validation – Кросс-валидация**  
Метод оценки обобщающих способностей модели путём разбиения данных на несколько обучающих и тестовых подмножеств. Этот подход позволяет более точно оценить производительность модели на новых данных и выявить проблемы переобучения.

**Residual Network (ResNet) – Остаточная сеть**  
Архитектура с пропускными (skip) связями, позволяющими строить очень глубокие сети и избегать проблемы затухающего градиента. Пропускные связи облегчают обучение, позволяя передавать информацию напрямую через несколько слоёв.

**Graph Neural Network (GNN) – Графовая нейронная сеть**  
Модель, предназначенная для обработки структурированных данных в виде графов, где связи между объектами имеют большое значение. GNN эффективно моделируют отношения между объектами, что важно для задач, связанных с социальными сетями, молекулярной химией и другими областями.

**Capsule Network – Капсульная сеть**  
Архитектура, стремящаяся сохранить пространственные иерархии между объектами, что полезно для задач распознавания изображений. Капсульные сети передают информацию о позиции, ориентации и других свойствах объектов, что делает их устойчивыми к трансформациям.

**DropConnect – Отбрасывание связей**  
Метод регуляризации, при котором случайным образом исключаются отдельные веса вместо нейронов целиком. Этот подход способствует уменьшению зависимости модели от конкретных параметров и улучшает её обобщающую способность.

**Sparse Coding – Разреженное кодирование**  
Техника представления данных с использованием небольшого числа активных элементов, что способствует экономичному описанию информации. Разреженное представление помогает выявлять наиболее значимые признаки и уменьшает избыточность в данных.

---

## LLM — большие языковые модели

**LLM (Large Language Model) – Большая языковая модель**  
Комплексная нейросеть, обученная на огромном количестве текстовых данных для генерации, анализа и понимания естественного языка. Такие модели способны улавливать тонкости языка, контекст и смысл, что позволяет им выполнять широкий спектр задач от перевода до создания творческих текстов.

**Language Modeling – Языковое моделирование**  
Задача предсказания следующего слова или символа в последовательности, лежащая в основе обучения языковых моделей. Эта задача помогает модели понять структуру языка и связи между словами, что является фундаментом для дальнейшего обучения.

**Pretraining – Предобучение**  
Этап обучения модели на большом корпусе текстов без специализированной разметки, позволяющий освоить языковые закономерности. Предобучение закладывает базовые знания, которые затем могут быть адаптированы под конкретные задачи с помощью тонкой настройки.

**Masked Language Modeling – Замаскированное языковое моделирование**  
Метод, при котором часть токенов заменяется специальными масками, а модель учится предсказывать замаскированные элементы. Этот подход помогает модели научиться учитывать контекст вокруг пропущенных слов, что улучшает её способность понимать и генерировать текст.

**Causal Language Modeling – Причинное языковое моделирование**  
Обучение модели предсказывать следующий токен на основе предыдущих, характерное для автогенеративных моделей. Такой подход позволяет моделям генерировать связный текст, основываясь на последовательном накоплении информации.

**Fine-tuning – Тонкая настройка**  
Доработка предобученной модели на специализированном наборе данных для повышения эффективности в конкретной задаче. Этот процесс позволяет адаптировать базовую модель под специфические требования и улучшить её точность на ограниченном наборе данных.

**Parameter Efficient Fine-Tuning – Эффективное дообучение**  
Методы адаптации крупных моделей с минимальными изменениями параметров (например, LoRA). Такой подход позволяет экономить вычислительные ресурсы и ускоряет процесс обучения, сохраняя при этом высокую точность.

**Token – Токен**  
Минимальная единица текста (слово, часть слова или символ), с которой работает модель. Разбиение текста на токены позволяет модели обрабатывать и анализировать данные на более мелком уровне, выявляя тонкие языковые нюансы.

**Prompt – Промт/Запрос/Подсказка**  
Входной текст, подаваемый модели для генерации ответа, от которого зависит качество результата. Правильно составленный запрос помогает модели понять контекст задачи и сгенерировать более релевантный ответ.

**Context Window – Контекстное окно**  
Ограничение на количество токенов, которое модель может одновременно учитывать, влияющее на «память» модели. Размер контекстного окна определяет, сколько информации из предыдущих слов модель способна обработать при генерации следующего токена.

**In-context Learning – Обучение в контексте**  
Способность модели адаптироваться к задаче на основе примеров, приведённых непосредственно в запросе. Такой подход позволяет модели использовать предоставленные примеры для улучшения предсказаний без дополнительного этапа обучения.

**Zero-shot Learning – Обучение без примеров**  
Возможность выполнения задачи на основе описания без предварительного примера. Модель, способная к zero-shot learning, демонстрирует высокий уровень обобщения, используя лишь свои базовые языковые знания.

**Few-shot Learning – Обучение с несколькими примерами**  
Метод, при котором в запросе предоставляется несколько примеров для лучшего понимания задачи. Этот подход позволяет модели адаптироваться к новым ситуациям, используя минимальное количество данных для демонстрации требуемой задачи.

**Chain-of-thought Reasoning – Цепочка рассуждений**  
Техника пошагового описания процесса решения задачи, повышающая прозрачность и точность вывода. Такой метод позволяет проследить логику, по которой модель приходит к ответу, что полезно для диагностики и улучшения её работы.

**Decoding – Декодирование**  
Процесс генерации текста из скрытых представлений модели; выбор алгоритма (жадный поиск, beam search) влияет на итоговый результат. Декодирование определяет, каким образом модель выбирает следующий токен, балансируя между разнообразием и точностью.

**Temperature – Температура**  
Гиперпараметр, регулирующий степень случайности в процессе генерации текста: низкое значение обеспечивает детерминированность, высокое – разнообразие. Изменяя температуру, можно контролировать креативность и предсказуемость выходного текста.

**Beam Search – Поиск по лучу**  
Алгоритм, одновременно рассматривающий несколько вариантов продолжения текста для выбора наиболее вероятного. Этот метод улучшает качество сгенерированного текста за счет учета нескольких перспектив при выборе следующего токена.

**Knowledge Distillation – Дистилляция знаний**  
Процесс переноса знаний от большой модели к меньшей для сокращения вычислительных затрат без значительной потери точности. Дистилляция помогает создать компактные модели, сохраняющие высокую производительность, что важно для практического применения.

**Multitask Learning – Мультитаскинг**  
Обучение модели выполнению нескольких задач одновременно, что способствует улучшению обобщающих способностей. Этот подход позволяет использовать взаимосвязанные задачи для повышения устойчивости и точности модели.

**Model Scaling – Масштабирование модели**  
Увеличение числа параметров и вычислительной мощности модели для повышения её производительности. Масштабирование часто приводит к улучшению качества предсказаний, хотя требует больше ресурсов и времени для обучения.

**Attention Mask – Маска внимания**  
Механизм, определяющий, какие токены учитывать в процессе вычисления внимания, что помогает избегать влияния паддинга. Маски внимания гарантируют, что модель фокусируется только на релевантной информации, улучшая качество генерации.

**Positional Encoding – Позиционное кодирование**  
Метод добавления информации о позиции токенов в последовательности для сохранения порядка слов в модели. Это позволяет моделям, не имеющим рекуррентной структуры, учитывать порядок элементов при обработке текста.

**Pretraining Objectives – Цели предобучения**  
Различные задачи (например, Next Sentence Prediction, Permuted Language Modeling) для обучения базовых языковых закономерностей. Эти цели помогают модели уловить структуру языка и зависимости между словами до применения к конкретным задачам.

**Scaling Laws – Законы масштабирования**  
Эмпирические зависимости, описывающие, как увеличение размера модели и объёма данных влияет на её производительность. Понимание этих закономерностей помогает оптимизировать архитектуру и выбор гиперпараметров для достижения лучших результатов.

**Multilingual Modeling – Мультиязычное моделирование**  
Подход, позволяющий обучать модели, способные работать с несколькими языками одновременно. Это значительно расширяет возможности применения моделей, позволяя обрабатывать и генерировать текст на разных языках без необходимости отдельного обучения для каждого из них.

---

## Computer Vision

**Image Classification – Классификация изображений**  
Задача определения категории, к которой принадлежит изображение. Модели классификации анализируют визуальные признаки и сопоставляют их с заранее определёнными классами, что применяется в распознавании объектов, медицинской диагностике и других областях.

**Object Detection – Обнаружение объектов**  
Процесс локализации и классификации объектов на изображении с помощью рамок или масок. Обнаружение объектов позволяет не только идентифицировать присутствующие элементы, но и определить их положение, что важно для систем видеонаблюдения и автономного вождения.

**Semantic Segmentation – Семантическая сегментация**  
Разбиение изображения на области, соответствующие различным классам, без выделения отдельных экземпляров. Этот метод позволяет детально анализировать сцену, присваивая каждому пикселю класс, что полезно для задач медицинской диагностики и анализа изображений.

**Instance Segmentation – Сегментация объектов**  
Метод, позволяющий выделять отдельные объекты и определять их класс в рамках одного изображения. В отличие от семантической сегментации, этот подход различает разные экземпляры объектов одного класса, что важно для точного анализа сложных сцен.

**Convolutional Neural Network (CNN) – Сверточная нейронная сеть**  
Архитектура, оптимизированная для обработки изображений посредством применения свёрток. CNN эффективно извлекают пространственные признаки из изображений, что делает их незаменимыми для задач классификации, обнаружения объектов и сегментации.

**Convolution – Свёртка**  
Операция, применяемая для извлечения локальных признаков из изображения с использованием фильтров. Свёртки помогают модели сосредоточиться на важных паттернах, таких как границы, текстуры и формы, что является фундаментом для последующего анализа.

**Pooling – Подвыборка**  
Операция уменьшения пространственных размеров представлений (например, max pooling, average pooling) для выделения устойчивых признаков. Подвыборка снижает вычислительную сложность и помогает модели стать инвариантной к небольшим смещениям в изображении.

**Feature Map – Карта признаков**  
Результат применения свёрточного фильтра к изображению, отражающий обнаруженные признаки. Карты признаков представляют собой «слой» информации, на котором выделены ключевые элементы, что позволяет дальше строить сложные представления.

**Image Preprocessing – Предобработка изображений**  
Методы подготовки изображений к анализу (нормализация, изменение размера, аугментация). Эти шаги помогают стандартизировать данные, улучшая качество обучения и повышая устойчивость моделей к шуму.

**Image Augmentation – Аугментация изображений**  
Методы искусственного увеличения объёма данных посредством применения преобразований (поворот, масштабирование, отражение). Аугментация помогает модели обучаться на более разнообразном наборе данных, снижая риск переобучения и улучшая обобщающие способности.

**Edge Detection – Выделение контуров**  
Алгоритмы для обнаружения границ объектов, способствующие выделению структурных особенностей изображения. Выделение контуров помогает понять форму и границы объектов, что может использоваться как предварительный этап анализа изображения.

**Optical Flow – Оптический поток**  
Метод оценки движения объектов в последовательности изображений или видеопотоке. Оптический поток позволяет моделям отслеживать перемещения и скорость объектов, что важно для видеоанализа и систем мониторинга.

**Pose Estimation – Определение позы**  
Задача определения положения и ориентации человека или объекта на изображении. Этот метод используется для анализа движений, распознавания действий и даже в развлекательных приложениях, таких как дополненная реальность.

**Generative Adversarial Networks (GAN) в CV**  
Применение GAN для генерации реалистичных изображений, улучшения качества или стилизации. GAN состоят из двух сетей – генератора и дискриминатора, которые обучаются в противоборстве, что позволяет создавать высококачественные изображения и улучшать существующие.

**Visual Transformers – Визуальные трансформеры**  
Адаптация архитектуры трансформеров для задач компьютерного зрения, позволяющая моделям работать с изображениями напрямую. Визуальные трансформеры успешно применяются для классификации, сегментации и обнаружения объектов, используя механизм внимания для выделения ключевых признаков.

**Region Proposal Network (RPN) – Сеть предложений регионов**  
Компонент, генерирующий кандидаты регионов на изображении для последующего обнаружения объектов. RPN позволяет эффективно выбирать потенциальные области, содержащие объекты, что значительно ускоряет и улучшает процесс детектирования.

**Feature Pyramid Network (FPN) – Сеть пирамиды признаков**  
Архитектура, объединяющая признаки на различных масштабах для улучшения точности обнаружения объектов. FPN позволяет моделям учитывать объекты разного размера, комбинируя высокоуровневые и низкоуровневые признаки.

**Style Transfer – Перенос стиля**  
Метод, позволяющий переносить художественный стиль одного изображения на контент другого. Эта технология находит применение в креативных задачах, позволяя создавать уникальные визуальные эффекты и изменять восприятие изображения.

**Super-Resolution – Сверхразрешение**  
Техника повышения разрешения изображения с восстановлением утраченных деталей. Модели сверхразрешения улучшают качество изображений, что особенно полезно для восстановления старых фотографий или улучшения изображений с низким разрешением.

**Semantic Instance Segmentation – Семантическая сегментация объектов**  
Комбинированный подход, объединяющий семантическую сегментацию и выделение отдельных экземпляров объектов. Этот метод позволяет одновременно определить класс объектов и их индивидуальные границы, что особенно важно для детального анализа сложных сцен.

---

## Reinforcement Learning

**Reinforcement Learning – Обучение с подкреплением**  
Область, в которой агент обучается на основе наград и штрафов, получаемых от взаимодействия с окружающей средой. Такой подход позволяет моделям самостоятельно учиться на основе опыта, оптимизируя стратегию действий для достижения заданных целей.

**Q-Learning – Q-обучение**  
Метод, при котором агент изучает оптимальную политику, оценивая Q-функцию — ожидаемую награду для пары состояние-действие. Q-Learning позволяет модели оценивать последствия своих действий и выбирать стратегию, которая максимизирует суммарную награду.

**Deep Q-Network (DQN) – Глубокая Q-сеть**  
Комбинация Q-обучения и нейронных сетей для работы с высокоразмерными пространствами состояний. DQN позволяет агентам успешно применять обучение с подкреплением в сложных средах, где традиционные методы не справляются из-за огромного количества возможных состояний.

**Policy Gradient – Градиент политики**  
Метод оптимизации, обновляющий параметры политики напрямую для максимизации ожидаемой награды. Такой подход позволяет агенту обучаться стратегии, не прибегая к оценке всех возможных вариантов действий, что особенно полезно в непрерывных пространствах.

**Actor-Critic – Актор-критик**  
Подход, где «актор» принимает решения, а «критик» оценивает их качество для корректировки стратегии. Этот метод сочетает преимущества как градиентного подхода, так и оценки ценности состояний, что ускоряет процесс обучения и улучшает стабильность.

**Proximal Policy Optimization (PPO) – Проксимальное оптимальное обучение политики**  
Алгоритм, обеспечивающий стабильное обновление политики посредством ограничения изменений в каждом шаге. PPO балансирует между исследованием новых стратегий и сохранением уже найденных эффективных решений, что позволяет избежать резких колебаний в обучении.

**Monte Carlo Tree Search (MCTS) – Монте-Карло поиск по дереву**  
Метод планирования, использующий симуляцию возможных исходов для принятия оптимальных решений. MCTS широко применяется в стратегических играх и сложных системах, где важно учитывать множество возможных вариантов развития событий.

**Exploration vs. Exploitation – Исследование vs. использование**  
Баланс между поиском новых стратегий (исследование) и применением уже известных для максимизации награды (использование). Этот принцип является ключевым в обучении с подкреплением и определяет эффективность обучения агента в динамической среде.

**SARSA – SARSA алгоритм**  
Метод обучения с подкреплением, в котором обновление производится на основе текущего действия и следующего шага, отражая последовательность состояний и действий. SARSA позволяет агенту корректировать свои решения, учитывая реальное поведение в среде, а не оптимистичные оценки.

**Double DQN – Двойная глубокая Q-сеть**  
Улучшенная версия DQN, снижающая переоценку Q-значений за счёт двойного оценивания. Этот метод обеспечивает более стабильное обучение и точное предсказание ценностей, что важно для сложных динамических систем.

**Prioritized Experience Replay – Приоритетный повтор опыта**  
Метод, позволяющий чаще использовать для обучения наиболее информативные переходы из опыта агента. Приоритетный повтор помогает ускорить обучение за счёт фокусировки на ошибках, которые несут наибольшую информационную ценность.

**Multi-Agent Reinforcement Learning – Мультиагентное обучение с подкреплением**  
Подход, в котором несколько агентов одновременно обучаются взаимодействовать в общей среде. Этот метод позволяет моделировать сложные системы, где агенты конкурируют или сотрудничают, что актуально для задач распределённого управления и игр.

**Inverse Reinforcement Learning – Обратное обучение с подкреплением**  
Метод, позволяющий восстановить функцию награды на основе наблюдаемого поведения эксперта. Этот подход используется для имитационного обучения, когда сложно формализовать награду, но есть примеры оптимального поведения.

---

## Additional Topics and Methods

**Self-Supervised Learning – Самостоятельное обучение**  
Метод, при котором модель обучается на данных без явных меток, извлекая скрытые закономерности. Эта техника позволяет использовать огромные объемы неразмеченных данных для предварительного обучения, что затем улучшает производительность на конкретных задачах.

**Meta-Learning – Мета-обучение**  
Подход, позволяющий моделям быстро адаптироваться к новым задачам с минимальным количеством примеров. Мета-обучение разрабатывает стратегии, которые облегчают последующее обучение, делая модели более универсальными и эффективными в изменяющихся условиях.

**Automated Machine Learning (AutoML) – Автоматизированное машинное обучение**  
Процесс автоматизации выбора моделей, гиперпараметров и этапов предобработки для оптимизации обучения. AutoML помогает снизить требования к экспертным знаниям, позволяя находить оптимальные решения быстрее и эффективнее.

**Adversarial Attacks – Атаки с использованием противоречивых примеров**  
Методы создания специально сформированных входных данных для проверки устойчивости моделей к ошибкам. Эти атаки демонстрируют уязвимости моделей, что стимулирует разработку более устойчивых и надежных решений.

**Robustness – Надёжность**  
Способность модели сохранять работоспособность при изменениях входных данных или внешних условиях. Повышение надежности важно для практических применений, где условия эксплуатации могут значительно варьироваться.

**Interpretability – Интерпретируемость**  
Способность модели предоставлять понятные объяснения своих решений, что важно для проверки корректности и доверия. Интерпретируемость помогает пользователям понять, как модель пришла к конкретному выводу, что особенно важно в критических приложениях.

**Explainability – Объяснимость**  
Процесс разработки инструментов для демонстрации причин, по которым модель приняла то или иное решение. Объяснимость повышает прозрачность моделей и позволяет выявлять потенциальные ошибки или предвзятость в алгоритмах.

**Continual Learning – Непрерывное обучение**  
Методика, позволяющая модели адаптироваться к новым данным, не забывая ранее изученное. Непрерывное обучение важно для систем, работающих в динамично меняющейся среде, где требуется постоянное обновление знаний.

**Few-Shot Meta-Learning – Мета-обучение с малым количеством примеров**  
Подход, позволяющий эффективно обучаться на ограниченном объёме данных с учётом предыдущего опыта. Этот метод особенно полезен в случаях, когда размеченных данных мало, позволяя модели быстро адаптироваться к новым задачам.

**Data Imbalance Handling – Работа с несбалансированными данными**  
Набор техник для корректного обучения на выборках с неравномерным распределением классов. Эти методы помогают избежать смещения модели в сторону более часто встречающихся классов, улучшая точность предсказаний для редких категорий.

**Causal Inference in DL – Причинный вывод в глубоких моделях**  
Методы выявления и анализа причинно-следственных связей в данных с использованием глубокого обучения. Этот подход позволяет моделям не только обнаруживать корреляции, но и понимать истинные взаимосвязи между переменными, что важно для интерпретации результатов.

**Neural Tangent Kernel (NTK) – Ядерный подход нейронных касательных**  
Теоретическая модель, позволяющая анализировать поведение бесконечно широких нейронных сетей и их обучение. NTK помогает исследовать теоретические аспекты глубокого обучения, давая возможность лучше понять динамику оптимизации и общие свойства сетей.
